\documentclass[12pt]{article}
\author{Alex Ho}
\title{FYS4150 - Computational Physics \\ Project 2}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[english, norsk]{babel}
\usepackage{xcolor}
\usepackage{hyperref}

\lstset{
language=Python,
basicstyle=\ttfamily,
otherkeywords={self},             
keywordstyle=\ttfamily\color{blue!90!black},
keywords=[2]{True,False},
%keywords=[3]{ttk},
keywordstyle={[2]\ttfamily\color{blue!90!black}},
emph={MyClass,__init__},          
emphstyle=\ttfamily\color{red!80!black},    
stringstyle=\color{blue!90!black},
showstringspaces=false,
commentstyle=\color{blue!90!black},
breaklines=true,
tabsize=3,
moredelim=**[is][\color{blue}]{@}{@}
}

\begin{document}
\maketitle
\section{Introduction}
In this project, we will have a look at the so called \textit{Eigenvalue problem}. We will use the well known Schrödinger equation from quantum mechanics and apply it to a system consisting of a single electron in a harmonic oscillator potential. To achieve this, we will implement Jacobi's method to solve the Schrödinger equation and then find the eigenvalues, which will physically be the energies of the electrons.

We will also look at the case where we have two interacting electrons in a three dimensional harmonic oscillator, with different frequencies.
\section{Method}
\subsection*{2a) Mathematical intermezzo}
We first want to look at the orthogonality properties of a specific basis. Let us consider the following basis of vectors
\begin{align}
\mathbf{v}_i = \begin{pmatrix}
v_{i1} \\
v_{i2} \\
\vdots \\
v_{in}
\end{pmatrix}
\end{align}
We will also assume that this is an orthogonal basis
\begin{align}
\mathbf{v}_j^T\mathbf{v}_i = \delta_{ij}
\end{align}
We want to look at the orthogonality properties for a orthogonal and unitary vector transformation in the form
\begin{align}
\mathbf{w}_i = \mathbf{U}\mathbf{v}_i
\end{align}
For an orthogonal matrix, we know that $\mathbf{U}^T\mathbf{U} = \mathbf{I}=1$, where $\mathbf{I}$ is the identity matrix, so we have that
\begin{align}
\mathbf{w}_j^T\mathbf{w}_i = (\mathbf{U}\mathbf{v}_i)^T(\mathbf{U}\mathbf{v}_i) = \mathbf{v}_j^T \mathbf{U}^T\mathbf{U}\mathbf{v}_i = \mathbf{v}_i^T\mathbf{v}_i = \delta{ij}
\end{align}
For a unitary matrix, we have that $\mathbf{U^*}\mathbf{U}=\mathbf{I}$ and $\mathbf{U}^{\dagger}\mathbf{U} = \mathbf{I}$, where $\mathbf{U}^{\dagger} = (\mathbf{U}^*)^T$ is the hermitian conjugate. Doing the hermitian conjugate on the transformation vector, we can show that
\begin{align}
\mathbf{w}_j^{\dagger}\mathbf{w}_i = (\mathbf{U}\mathbf{v}_j)^{\dagger}(\mathbf{U}\mathbf{v}_i) = \mathbf{v}_j^{\dagger}\mathbf{U}^{\dagger}\mathbf{U}\mathbf{v}_i = \mathbf{v}_j^{\dagger}\mathbf{v}_i = \delta_{ij}
\end{align}
Here we have assumed that the basis vector is real, so $\mathbf{v}_i^* = \mathbf{v}_i$.
\subsection*{2b) Jacobi's rotation method}
Jacobi's rotation method (or Jacobi's method) is an algorithm that can be used to solve the eigenvalue problem. Consider an $n\times n$ orthogonal transformation matrix
\begin{align}
\mathbf{S} = \begin{pmatrix}
1 & 0 & \cdots & 0 & 0 & \cdots & 0 & 0 \\
0 & 1 & \cdots & 0 & 0 & \cdots & 0 & 0 \\
\cdots & \cdots & \cdots & \cdots &\cdots & \cdots & \cdots & \cdots \\
0 & 0& \cdots & \cos \theta & 0 & \cdots & 0 & \sin \theta \\
0 & 0 & \cdots & 0 & 1 & \cdots & 0 & 0 \\
0 & \cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & 0 & 0 & \cdots & 1 & 0 \\
0 & 0 & \cdots & -\sin\theta & 0 & \cdots & 0 & \cos\theta
\end{pmatrix}
\end{align}
with the property $\mathbf{S}^T = \mathbf{S}^{-1}$. A similarity transformation, on a matrix $\mathbf{A}$
\begin{align}
\mathbf{B} = \mathbf{S}^T \mathbf{A} \mathbf{S}
\end{align}
gives us 
\begin{align}
b_{ii} &= a_{ii} ,\quad i\neq k, i\neq l \\
b_{ik} &= a_{ik} \cos\theta - a_{il}\sin\theta, \quad i\neq k, i\neq j \\
b_{il} &= a_{il}\cos\theta + a_{ik}\sin\theta, \quad i\neq k, i\neq j \\
b_{kk} &= a_{kk}\cos^2\theta - 2a_{kl}\cos\theta\sin\theta + a_{ll}\sin^2\theta \\
b_{ll} &= a_{ll}\cos^2\theta + 2a_{kl}\cos\theta\sin\theta + a_{kk}\sin^2\theta \\
b_{kl} &= (a_{kk}-a_{ll})\cos\theta\sin\theta + a_{kl}(\cos^2\theta - \sin^2\theta)
\end{align}
The angle $\theta$ is arbitrary. The idea here is to choose a $\theta$ that causes all non-diagonal matrix elements to become zero (or within a given tolerance). However, not all non-diagonal matrix elements will become zero after one iteration, so we will have to run this algorithm a sufficient amount of times to get the desired result.

Since we want the non-diagonal matrix elements to become zero, we require that $b_{kl} = b_{lk} = 0$, which gives
\begin{align}
b_{kl} = (a_{kk} - a_{ll})\cos\theta\sin\theta + a_{kl}(\cos^2\theta - \sin^2\theta) = 0
\end{align}
\section{Implementation}
\section{Results}
\section{Conclusion}
\section{References}
M. Hjort-Jensen, 2015, \textit{Computational Physics}, accessible at course GitHub repository; \url{https://github.com/CompPhysics/ComputationalPhysics/tree/master/doc/Lectures} (as of 14.09.16), 551 pages.
\end{document}